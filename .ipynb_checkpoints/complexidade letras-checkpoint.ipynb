{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2ca97f-30f1-4323-8f09-f0896105afa2",
   "metadata": {},
   "source": [
    "# Complexidade de letras:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4213ad4a-ffe4-4cdf-a4c3-8f33968cac1c",
   "metadata": {},
   "source": [
    "Este código foi desenvolvido para explorar e revelar a riqueza das letras musicais, proporcionando uma análise de sua complexidade lírica. Abaixo, apresentamos os critérios utilizados na análise:\n",
    "\n",
    "Número de sílabas:\n",
    "Palavras com múltiplas sílabas geralmente apresentam maior complexidade, tanto em termos de compreensão quanto de pronúncia.\n",
    "\n",
    "Frequência:\n",
    "A frequência das palavras na letra pode indicar sua acessibilidade e familiaridade para o público.\n",
    "\n",
    "Análise gramatical:\n",
    "Frases que utilizam muitos gerúndios tendem a ser mais coloquiais, enquanto aquelas que incorporam um maior número de conjunções subordinadas costumam ser mais formais.\n",
    "\n",
    "Diversidade lexical:\n",
    "A variedade de vocabulário e a riqueza semântica do texto contribuem para a profundidade e a expressividade das letras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2029dc70-beaf-4028-93b0-34abf77e870a",
   "metadata": {},
   "source": [
    "Importando todas as bibliotecas usadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e45b74a6-20d3-43bc-8e3f-6053987b6d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textstat as tst\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5ff4272c-6bbf-4b5c-ad61-9dbe413bef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tcc_ceds_music.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d77b9-04ee-4cab-bc88-f1703099ccae",
   "metadata": {},
   "source": [
    "### Número de sílabas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f5cfd200-3ce4-419b-8db8-713ee9e23948",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {df.track_name[n]: {} for n in range(len(df))} #Para evitar que músicas de nomes iguais recebessem o mesmo número de sílabas, foi necessário colocar um index\n",
    "\n",
    "for n in range(len(df)):\n",
    "    lista = df.lyrics[n].split(\" \")\n",
    "    for palavra in lista:\n",
    "        if palavra not in dic[df.track_name[n]]:\n",
    "            dic[df.track_name[n]][palavra] = tst.syllable_count(palavra)\n",
    "\n",
    "musicas_silabas_complexas = {}\n",
    "\n",
    "for nome_musica, palavras in dic.items():\n",
    "    for palavra, silabas in palavras.items():\n",
    "        if silabas >= 4:\n",
    "            if not any(palavra.count(letra) >= 4 for letra in set(palavra)): #Como em músicas é muito comum expressões como: \"Ahhh\", \"Ohhh\", foi necessário filtrá-las\n",
    "                if nome_musica not in musicas_silabas_complexas:\n",
    "                    musicas_silabas_complexas[nome_musica] = 1\n",
    "                else:\n",
    "                    musicas_silabas_complexas[nome_musica] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3d705f7c-8824-443d-8056-7bf0f026ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Silabas'] = df['track_name'].map(musicas_silabas_complexas).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc2781b-78b0-457f-83e4-56683178833f",
   "metadata": {},
   "source": [
    "Explicação: O código cria um dicionário (dic) onde as chaves são os nomes das músicas e os valores são dicionários que armazenam palavras e suas contagens de sílabas. Para cada música no DataFrame, as letras são divididas em palavras e, para cada palavra, o número de sílabas é contado utilizando a função tst.syllable_count. Em seguida, um segundo dicionário (musicas_silabas_complexas) é construído para identificar músicas com palavras que têm 6 ou mais sílabas, desde que essas palavras não contenham mais de três repetições de qualquer letra. Se uma palavra atende a esses critérios, o contador correspondente à música é incrementado. Assim, o código visa identificar e contar músicas que possuem palavras mais complexas em termos de sílabas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe4811-74e6-4722-b75b-4fc6a9c8a792",
   "metadata": {},
   "source": [
    "### Frequência:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b8b506c-ed9a-4320-b683-568f8c206d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_unicas_list = []\n",
    "lista_ttr = []\n",
    "\n",
    "for letra in range(len(df)):\n",
    "    palavras = df.lyrics[letra].lower().split()\n",
    "    palavras_unicas_list.append(len(set(palavras)))\n",
    "    \n",
    "for n in range(len(palavras_unicas_list)):\n",
    "    lista_ttr.append(palavras_unicas_list[n]/df.len[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8171e899-7066-4588-8246-8dad57fdd6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Diversidade lexical\"] = lista_ttr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd8b76-3167-4043-8af2-0b558c74eb7b",
   "metadata": {},
   "source": [
    "Explicação: O Type-Token Ratio (TTR) mede a diversidade lexical de um texto, representando a relação entre o número de palavras únicas e o total de palavra. Essa métrica permite comparar estilos de escrita entre diferentes letras de músicas ou autores e serve como indicador da complexidade linguística, onde letras mais desafiadoras tendem a ter um TTR maior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5928d184-7a25-4878-bd7f-f953828f906a",
   "metadata": {},
   "source": [
    "### Análise Gramatical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "53ab9ae5-340f-4060-b5a4-f266c75367b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tags = {track: 0 for track in df['track_name']}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    tokens = word_tokenize(row['lyrics'].lower())\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    pontuacao = 0\n",
    "    for palavra, tag in tags:\n",
    "\n",
    "        if tag in ['NNP', 'NNPS']: #NNP: substantivo próprio, sigular. NNPS: substantivo próprio, plural\n",
    "            pontuacao += 0.02\n",
    "        elif tag in ['JJ', 'JJR', 'JJS']: #JJ: Adjetivo. JJR: adjetivo comparativo. JJS: adjetivo superlativo\n",
    "            pontuacao += 0.01\n",
    "        elif tag in ['RB', 'RBR', 'RBS']: #RB: advérbio. RBR: advérbio comparativo. RBS: advérbio superlativo.\n",
    "            pontuacao += 0.01\n",
    "        elif tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']: #VB: verbo. VBD: verbo passado. VBG: verbo gerúndio ou particípio presente. VBN: verbo particípio passado. VBP: verbo presente não 3ª pessoa singular. VBZ: verbo, presente, 3ª pessoa singular\n",
    "            pontuacao += 0.01\n",
    "        elif tag == 'WDT': #WDT: determinante interrogativo\n",
    "            pontuacao += 0.01 \n",
    "        elif tag == 'IN': # IN: preposição ou conjunção subordinativa \n",
    "            pontuacao += 0.01\n",
    "            \n",
    "    dic_tags[row['track_name']] = pontuacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c3fe25e2-df62-41fd-b8c8-e0f362663f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pontuacao gramatica'] = df['track_name'].map(dic_tags).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40465b4-38c3-4b8e-acda-8d79b83ce89d",
   "metadata": {},
   "source": [
    "Explicação: Usando a biblioteca NLTK, é possível analisar palavra por palavra, determinando sua classe gramatical. Desse modo, as letras foram lidas e tiveram uma pontuação atribuída relacionada à presença de determinadas classes gramaticais que tornam o texto mais complexo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c82ee-691f-43bb-a40c-c021ab1b13ce",
   "metadata": {},
   "source": [
    "### Diversidade Lexical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1a178134-4532-4567-8d22-dc1b49e76cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e6bc55-ceee-4883-a8ce-73a97bffdeaf",
   "metadata": {},
   "source": [
    "Para que o modelo consiga ler as letras, é necessário separá-las em listas, onde cada palavra estará separada por vírgulas. Além disso, para melhor eficácia do modelo, removi as stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fa10fe14-2d0f-4626-ad68-839ec5e8a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "letras = [[letra for letra in df['lyrics'][n].split() if letra not in stop_words] for n in range(len(df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f917e1-7b72-41a6-accf-3c14301d9f92",
   "metadata": {},
   "source": [
    "Para o processamento, é necessário passar a lista como parâmetro, onde o modelo aprende as representações vetoriais das palavras com base em suas coocorrências no texto, resultando em um modelo que pode capturar relações semânticas e contextuais entre as palavras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bdf6e1c4-d21a-4803-a1c3-43dd35a8b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(letras, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2edb76-201b-4972-9be8-84942086523a",
   "metadata": {},
   "source": [
    "Como o model leu todas as palavras presentes no dataset, ele consegue, baseado principalmente pela coocorência, transformar as palavras em vetores, facilitando a análise delas. Desse modo, para analisar a complexidade, irei usar a variabilidade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ea491c1f-1a30-45ee-84a6-c29ef3f0f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complexidade_vetores(palavras, modelo):\n",
    "    vetores = []\n",
    "    for palavra in palavras:\n",
    "        if palavra in modelo.wv:\n",
    "            vetores.append(modelo.wv[palavra]) #modelo.wv[palavra] retorna o vetor relacionado à palavra\n",
    "            \n",
    "    vetores_np = np.array(vetores)\n",
    "    variancia = np.var(vetores_np, axis=0)\n",
    "\n",
    "    return np.sum(variancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aeb988eb-db9d-4bef-850e-6a9fd87b6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_complexidade(letra, modelo):\n",
    "    letra_processada = [palavra.lower() for palavra in letra.split()]\n",
    "    return complexidade_vetores(letra_processada, modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d3d1ca55-8d2a-4791-85ca-1baf8c55c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_complexidade = {df.track_name[n]: {} for n in range(len(df))} \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    letra = row['lyrics']\n",
    "    complexidade = calcular_complexidade(letra, model)\n",
    "    dic_complexidade[df.track_name[index]] = complexidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c459671f-474b-4e99-839d-dea627ce1e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "complexidades = [calcular_complexidade(letra, model) for letra in df['lyrics']]\n",
    "q1 = np.percentile(complexidades, 25)\n",
    "q3 = np.percentile(complexidades, 75)\n",
    "mediana = np.median(complexidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9ac65d9e-e200-4f23-a970-6eba34f1a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dic_complexidade.items():\n",
    "    if value < q1:\n",
    "        df.loc[df['track_name'] == key, \"variabilidade\"] = 1\n",
    "    elif q1 < value < mediana:\n",
    "        df.loc[df['track_name'] == key, \"variabilidade\"] = 2\n",
    "    elif mediana < value < q3:\n",
    "        df.loc[df['track_name'] == key, \"variabilidade\"] = 3\n",
    "    else:\n",
    "       df.loc[df['track_name'] == key, \"variabilidade\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4b58ff98-9830-4a75-a0ba-91c31228eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "peso_silabas = 1\n",
    "peso_diversidade = 2\n",
    "peso_gramatica = 1.5\n",
    "peso_variabilidade = 1\n",
    "\n",
    "df['complexidade_total'] = (\n",
    "    peso_silabas * df['Silabas'] +\n",
    "    peso_diversidade * df['Diversidade lexical'] +\n",
    "    peso_gramatica * df['Pontuacao gramatica'] +\n",
    "    peso_variabilidade * df['variabilidade']\n",
    ")\n",
    "\n",
    "media = df['complexidade_total'].mean()\n",
    "desvio_padrao = df['complexidade_total'].std()\n",
    "limite_superior = media + desvio_padrao\n",
    "\n",
    "df['complexa'] = (df['complexidade_total'] > limite_superior).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d9564dab-e0af-49ea-8551-861792976d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset_complexidade.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "77c2ef12-ff05-4d44-aa99-d7abbb6c1ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "      <th>Silabas</th>\n",
       "      <th>Diversidade lexical</th>\n",
       "      <th>Pontuacao gramatica</th>\n",
       "      <th>variabilidade</th>\n",
       "      <th>complexidade_total</th>\n",
       "      <th>complexa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>16425</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>hot n cold</td>\n",
       "      <td>2008</td>\n",
       "      <td>pop</td>\n",
       "      <td>change mind like girl change clothe yeah like ...</td>\n",
       "      <td>92</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.327707</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857791</td>\n",
       "      <td>0.839835</td>\n",
       "      <td>violence</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.423913</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.642826</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5928</th>\n",
       "      <td>17077</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>the one that got away</td>\n",
       "      <td>2010</td>\n",
       "      <td>pop</td>\n",
       "      <td>summer high school mustang radiohead birthday ...</td>\n",
       "      <td>74</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.375478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878401</td>\n",
       "      <td>0.795789</td>\n",
       "      <td>world/life</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.927297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6110</th>\n",
       "      <td>17615</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>part of me</td>\n",
       "      <td>2012</td>\n",
       "      <td>pop</td>\n",
       "      <td>days like want drive away pack bag watch fade ...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759893</td>\n",
       "      <td>0.922921</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.465000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6158</th>\n",
       "      <td>17758</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>wide awake</td>\n",
       "      <td>2012</td>\n",
       "      <td>pop</td>\n",
       "      <td>wide awake wide awake wide awake yeah dark fal...</td>\n",
       "      <td>133</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568219</td>\n",
       "      <td>0.683674</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383459</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.126917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>18082</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>unconditionally</td>\n",
       "      <td>2013</td>\n",
       "      <td>pop</td>\n",
       "      <td>close inside insecurities dirty laundry blink ...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.096705</td>\n",
       "      <td>0.087727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344600</td>\n",
       "      <td>0.725717</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.585000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6311</th>\n",
       "      <td>18189</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>this is how we do</td>\n",
       "      <td>2013</td>\n",
       "      <td>pop</td>\n",
       "      <td>ohoh sip rosé silver lake come lazy slow cook ...</td>\n",
       "      <td>152</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800082</td>\n",
       "      <td>0.636625</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.926316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6790</th>\n",
       "      <td>19515</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>swish swish</td>\n",
       "      <td>2017</td>\n",
       "      <td>pop</td>\n",
       "      <td>know know strut fuck tiger lose sleep need opi...</td>\n",
       "      <td>159</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.036251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568219</td>\n",
       "      <td>0.705697</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.597484</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.514969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 artist_name             track_name  release_date genre  \\\n",
       "5702       16425  katy perry             hot n cold          2008   pop   \n",
       "5928       17077  katy perry  the one that got away          2010   pop   \n",
       "6110       17615  katy perry             part of me          2012   pop   \n",
       "6158       17758  katy perry             wide awake          2012   pop   \n",
       "6270       18082  katy perry        unconditionally          2013   pop   \n",
       "6311       18189  katy perry      this is how we do          2013   pop   \n",
       "6790       19515  katy perry            swish swish          2017   pop   \n",
       "\n",
       "                                                 lyrics  len    dating  \\\n",
       "5702  change mind like girl change clothe yeah like ...   92  0.000658   \n",
       "5928  summer high school mustang radiohead birthday ...   74  0.000892   \n",
       "6110  days like want drive away pack bag watch fade ...  100  0.000605   \n",
       "6158  wide awake wide awake wide awake yeah dark fal...  133  0.000424   \n",
       "6270  close inside insecurities dirty laundry blink ...   50  0.001698   \n",
       "6311  ohoh sip rosé silver lake come lazy slow cook ...  152  0.016393   \n",
       "6790  know know strut fuck tiger lose sleep need opi...  159  0.018646   \n",
       "\n",
       "      violence  world/life  ...   valence    energy       topic       age  \\\n",
       "5702  0.327707    0.038986  ...  0.857791  0.839835    violence  0.171429   \n",
       "5928  0.000892    0.375478  ...  0.878401  0.795789  world/life  0.142857   \n",
       "6110  0.000605    0.000605  ...  0.759893  0.922921     sadness  0.114286   \n",
       "6158  0.000424    0.000424  ...  0.568219  0.683674     sadness  0.114286   \n",
       "6270  0.096705    0.087727  ...  0.344600  0.725717     sadness  0.100000   \n",
       "6311  0.000619    0.000619  ...  0.800082  0.636625     obscene  0.100000   \n",
       "6790  0.000627    0.036251  ...  0.568219  0.705697     obscene  0.042857   \n",
       "\n",
       "      Silabas  Diversidade lexical  Pontuacao gramatica  variabilidade  \\\n",
       "5702      1.0             0.423913                 0.53            4.0   \n",
       "5928      1.0             0.648649                 0.42            4.0   \n",
       "6110      0.0             0.440000                 0.39            3.0   \n",
       "6158      0.0             0.383459                 0.24            3.0   \n",
       "6270      3.0             0.500000                 0.39            2.0   \n",
       "6311      1.0             0.513158                 0.60            1.0   \n",
       "6790      0.0             0.597484                 0.88            1.0   \n",
       "\n",
       "      complexidade_total  complexa  \n",
       "5702            6.642826         1  \n",
       "5928            6.927297         1  \n",
       "6110            4.465000         0  \n",
       "6158            4.126917         0  \n",
       "6270            6.585000         1  \n",
       "6311            3.926316         0  \n",
       "6790            3.514969         0  \n",
       "\n",
       "[7 rows x 37 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"artist_name\"] == \"katy perry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c07d92-f0e4-4041-8aaf-93ab55c0b2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
