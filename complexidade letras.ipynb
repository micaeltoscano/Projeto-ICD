{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2ca97f-30f1-4323-8f09-f0896105afa2",
   "metadata": {},
   "source": [
    "# Complexidade de letras:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4213ad4a-ffe4-4cdf-a4c3-8f33968cac1c",
   "metadata": {},
   "source": [
    "Este código foi desenvolvido para explorar e revelar a riqueza das letras musicais, proporcionando uma análise de sua complexidade lírica. Abaixo, apresentamos os critérios utilizados na análise:\n",
    "\n",
    "Número de sílabas:\n",
    "Palavras com múltiplas sílabas geralmente apresentam maior complexidade, tanto em termos de compreensão quanto de pronúncia.\n",
    "\n",
    "Frequência:\n",
    "A frequência das palavras na letra pode indicar sua acessibilidade e familiaridade para o público.\n",
    "\n",
    "Análise gramatical:\n",
    "Frases que utilizam muitos gerúndios tendem a ser mais coloquiais, enquanto aquelas que incorporam um maior número de conjunções subordinadas costumam ser mais formais.\n",
    "\n",
    "Diversidade lexical:\n",
    "A variedade de vocabulário e a riqueza semântica do texto contribuem para a profundidade e a expressividade das letras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2029dc70-beaf-4028-93b0-34abf77e870a",
   "metadata": {},
   "source": [
    "Importando todas as bibliotecas usadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45b74a6-20d3-43bc-8e3f-6053987b6d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textstat as tst\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff4272c-6bbf-4b5c-ad61-9dbe413bef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tcc_ceds_music.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d77b9-04ee-4cab-bc88-f1703099ccae",
   "metadata": {},
   "source": [
    "### Número de sílabas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5cfd200-3ce4-419b-8db8-713ee9e23948",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {df.track_name[n]: {} for n in range(len(df))} #Para evitar que músicas de nomes iguais recebessem o mesmo número de sílabas, foi necessário colocar um index\n",
    "\n",
    "for n in range(len(df)):\n",
    "    lista = df.lyrics[n].split(\" \")\n",
    "    for palavra in lista:\n",
    "        if palavra not in dic[df.track_name[n]]:\n",
    "            dic[df.track_name[n]][palavra] = tst.syllable_count(palavra)\n",
    "\n",
    "musicas_silabas_complexas = {}\n",
    "\n",
    "for nome_musica, palavras in dic.items():\n",
    "    for palavra, silabas in palavras.items():\n",
    "        if silabas >= 6:\n",
    "            if not any(palavra.count(letra) >= 4 for letra in set(palavra)): #Como em músicas é muito comum expressões como: \"Ahhh\", \"Ohhh\", foi necessário filtrá-las\n",
    "                if nome_musica not in musicas_silabas_complexas:\n",
    "                    musicas_silabas_complexas[nome_musica] = 1\n",
    "                else:\n",
    "                    musicas_silabas_complexas[nome_musica] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d705f7c-8824-443d-8056-7bf0f026ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['silabas'] = df['track_name'].map(musicas_silabas_complexas).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc2781b-78b0-457f-83e4-56683178833f",
   "metadata": {},
   "source": [
    "Explicação: O código cria um dicionário (dic) onde as chaves são os nomes das músicas e os valores são dicionários que armazenam palavras e suas contagens de sílabas. Para cada música no DataFrame, as letras são divididas em palavras e, para cada palavra, o número de sílabas é contado utilizando a função tst.syllable_count. Em seguida, um segundo dicionário (musicas_silabas_complexas) é construído para identificar músicas com palavras que têm 6 ou mais sílabas, desde que essas palavras não contenham mais de três repetições de qualquer letra. Se uma palavra atende a esses critérios, o contador correspondente à música é incrementado. Assim, o código visa identificar e contar músicas que possuem palavras mais complexas em termos de sílabas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe4811-74e6-4722-b75b-4fc6a9c8a792",
   "metadata": {},
   "source": [
    "### Frequência:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b8b506c-ed9a-4320-b683-568f8c206d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_unicas_list = []\n",
    "lista_ttr = []\n",
    "\n",
    "for letra in range(len(df)):\n",
    "    palavras = df.lyrics[letra].lower().split()\n",
    "    palavras_unicas_list.append(len(set(palavras)))\n",
    "    \n",
    "for n in range(len(palavras_unicas_list)):\n",
    "    lista_ttr.append(palavras_unicas_list[n]/df.len[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd8b76-3167-4043-8af2-0b558c74eb7b",
   "metadata": {},
   "source": [
    "Explicação: O Type-Token Ratio (TTR) mede a diversidade lexical de um texto, representando a relação entre o número de palavras únicas e o total de palavra. Essa métrica permite comparar estilos de escrita entre diferentes letras de músicas ou autores e serve como indicador da complexidade linguística, onde letras mais desafiadoras tendem a ter um TTR maior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5928d184-7a25-4878-bd7f-f953828f906a",
   "metadata": {},
   "source": [
    "### Análise Gramatical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53ab9ae5-340f-4060-b5a4-f266c75367b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tags = {track: 0 for track in df['track_name']}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    tokens = word_tokenize(row['lyrics'].lower())\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    pontuacao = 0\n",
    "    for palavra, tag in tags:\n",
    "\n",
    "        if tag in ['NNP', 'NNPS']: #NNP: substantivo próprio, sigular. NNPS: substantivo próprio, plural\n",
    "            pontuacao += 2\n",
    "        elif tag in ['JJ', 'JJR', 'JJS']: #JJ: Adjetivo. JJR: adjetivo comparativo. JJS: adjetivo superlativo\n",
    "            pontuacao += 1\n",
    "        elif tag in ['RB', 'RBR', 'RBS']: #RB: advérbio. RBR: advérbio comparativo. RBS: advérbio superlativo.\n",
    "            pontuacao += 1\n",
    "        elif tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']: #VB: verbo. VBD: verbo passado. VBG: verbo gerúndio ou particípio presente. VBN: verbo particípio passado. VBP: verbo presente não 3ª pessoa singular. VBZ: verbo, presente, 3ª pessoa singular\n",
    "            pontuacao += 1\n",
    "        elif tag == 'WDT': #WDT: determinante interrogativo\n",
    "            pontuacao += 1 \n",
    "        elif tag == 'IN': # IN: preposição ou conjunção subordinativa \n",
    "            pontuacao += 1\n",
    "            \n",
    "    dic_tags[row['track_name']] = pontuacao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40465b4-38c3-4b8e-acda-8d79b83ce89d",
   "metadata": {},
   "source": [
    "Explicação: Usando a biblioteca NLTK, é possível analisar palavra por palavra, determinando sua classe gramatical. Desse modo, as letras foram lidas e tiveram uma pontuação atribuída relacionada à presença de determinadas classes gramaticais que tornam o texto mais complexo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c82ee-691f-43bb-a40c-c021ab1b13ce",
   "metadata": {},
   "source": [
    "### Diversidade Lexical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a178134-4532-4567-8d22-dc1b49e76cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e6bc55-ceee-4883-a8ce-73a97bffdeaf",
   "metadata": {},
   "source": [
    "Para que o modelo consiga ler as letras, é necessário separá-las em listas, onde cada palavra estará separada por vírgulas. Além disso, para melhor eficácia do modelo, removi as stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa10fe14-2d0f-4626-ad68-839ec5e8a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "letras = [[letra for letra in df['lyrics'][n].split() if letra not in stop_words] for n in range(len(df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f917e1-7b72-41a6-accf-3c14301d9f92",
   "metadata": {},
   "source": [
    "Para o processamento, é necessário passar a lista como parâmetro, onde o modelo aprende as representações vetoriais das palavras com base em suas coocorrências no texto, resultando em um modelo que pode capturar relações semânticas e contextuais entre as palavras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdf6e1c4-d21a-4803-a1c3-43dd35a8b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(letras, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2edb76-201b-4972-9be8-84942086523a",
   "metadata": {},
   "source": [
    "Como o model leu todas as palavras presentes no dataset, ele consegue, baseado principalmente pela coocorência, transformar as palavras em vetores, facilitando a análise delas. Desse modo, para analisar a complexidade, irei usar a variabilidade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea491c1f-1a30-45ee-84a6-c29ef3f0f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complexidade_vetores(palavras, modelo):\n",
    "    vetores = []\n",
    "    for palavra in palavras:\n",
    "        if palavra in modelo.wv:\n",
    "            vetores.append(modelo.wv[palavra]) #modelo.wv[palavra] retorna o vetor relacionado à palavra\n",
    "            \n",
    "    vetores_np = np.array(vetores)\n",
    "    variancia = np.var(vetores_np, axis=0)\n",
    "\n",
    "    return np.sum(variancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeb988eb-db9d-4bef-850e-6a9fd87b6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_complexidade(letra, modelo):\n",
    "    letra_processada = [palavra.lower() for palavra in letra.split()]\n",
    "    return complexidade_vetores(letra_processada, modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3d1ca55-8d2a-4791-85ca-1baf8c55c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_complexidade = {df.track_name[n]: {} for n in range(len(df))} \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    letra = row['lyrics']\n",
    "    complexidade = calcular_complexidade(letra, model)\n",
    "    dic_complexidade[df.track_name[index]] = complexidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459671f-474b-4e99-839d-dea627ce1e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "complexidades = [calcular_complexidade(letra, model, stop_words) for letra in df['lyrics']]\n",
    "q1 = np.percentile(complexidades, 25)\n",
    "q3 = np.percentile(complexidades, 75)\n",
    "mediana = np.median(complexidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac65d9e-e200-4f23-a970-6eba34f1a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dic_complexidade.items():\n",
    "    if value < q1:\n",
    "        df.loc[df['track_name'] == key, \"variabilidade\"] = 1\n",
    "    elif q1 < value < mediana:\n",
    "        df.loc[df['track_name'] == key, \"variabilidade\"] = 2\n",
    "    elif mediana < value < q3:\n",
    "        df.loc[df['track_name'] == key, \"variabilidade\"] = 3\n",
    "    else:\n",
    "       df.loc[df['track_name'] == key, \"variabilidade\"] = 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
